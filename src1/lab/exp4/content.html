<!-- This file needs to be edited by the lab developer to suit
the requirements of their lab in particular.-->

<!-- Add class="default" to include any element as it is
specified in default.html. 
Do not include class="default" to the elements that you want to
edit -->

<!DOCTYPE html>
<html>
<head></head>
<body>

<div id="experiment"> <!-- The Experiment Document Container-->

  <!-- The lab Header contains the logo and the name of the lab,
  usually displayed on the top of the page-->

  <header id="experiment-header" class="default">
  
    <div id="experiment-header-logo" class="logo">
      <!-- Enclose the logo image of your lab or write it in 
      text-->
      <img src="../images/logo.jpg" />
    </div>

    <div id="experiment-header-heading" class="heading">
      <!-- Write the name of your lab and link it to the home 
      page of your lab (h1 tag is preferred while writing your 
      lab name)-->
      <a href="../index.html">Natural Language Processing Lab</a>	
    </div>

    <!-- Add any additional element you want to add to the lab 
    header, For example : Help (Enclosing them with suitable 
    div is recommended)-->

  </header>


  <!-- The lab article is the main content area where all the 
  experiment content sits-->
  <article id="experiment-article">
  
    <!-- The lab article has an header, optional navigational 
    menu, number of sections, an optional sidebar and a closing 
    footer-->
     <div id="experiment-article-breadcrumb" class="breadcrumb">
     </div>
    
      <header id="experiment-article-heading" class="heading">
        <!-- You can add a welcome message or title of the 
        experiment here -->
        N-Grams
        <!-- Add any additional element if required with proper 
        enclosing-->
      </header>

      <!-- Navigation menu is useful to organize the view of 
      multiple sections inside the article-->
      <nav id="experiment-article-navigation" class="default">
        <ul id="experiment-article-navigation-menu">
          <!-- The menu can be dynamically generated to contain 
          the headings of your sections or instead write the 
          menu items of your choice individually enclosedu in 
          <li> tag as shown below-->
        </ul>
      </nav>

      <!-- All the sections of your lab or experiment can be 
      enclosed together with a div element as shown below-->
      <div id="experiment-article-sections">

        <!-- First section of the article-->
        <section id="experiment-article-section-1">
          
          <div id="experiment-article-section-1-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab -->
	    <img src="../images/introduction.jpg" />
	  </div>	
          
          <!-- The heading for the section can be enclosed in a 
          div tag. -->
          <div id="experiment-article-section-1-heading" 
          class="heading">
            Introduction
          </div>

          <!-- Write the section content inside a paragraph 
          element, You can also include images with <img> tag -->
          <div id="experiment-article-section-1-content" 
          class="content">	
Probability of a sentence can be calculated by the probability of sequence of words occuring in it. We can use Markov assumption, that the probability of a word in a sentence depends on the probability of the word occuring just before it. Such a model is called first order Markov model or the bigram model. <br/>

<center><img src="Exp9/9-a.jpg" alt="1_alt" style="height:50px; width:400px"/></center><br/>

Here, W<sub>n</sub> refers to the word token corresponding to the nth word in a sequence.   
<br><br><hr>
        </div>


      </section>

      <!-- Second section of the article-->
      <section id="experiment-article-section-2">
        
        <div id="experiment-article-section-2-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/theory.jpg" />
	</div>
				
        <!-- The heading for the section can be enclosed in a 
        div tag. -->
        <div id="experiment-article-section-2-heading" 
        class="heading">
          Theory
        </div>


        <!-- Write the section content inside a paragraph 
        element, we can also include images with <img> tag -->
<div id="experiment-article-section-2-content" 
        class="content">
A combination of words forms a sentence. However, such a formation is meaningful  only when the words are arranged in some order. <br/>
Eg:  Sit I car in the<br/>
Such a sentence is not grammatically acceptable. However some perfectly grammatical sentences can be nonsensical too!<br/>
Eg: Colorless green ideas sleep furiously<br/>
One easy way to handle such unacceptable sentences is by assigning probabilities to the strings of words i.e, how likely the sentence is. <br/>
<br/>
<b><u> Probability of a sentence </u></b><br/>

If we consider each word occurring in its correct location as an independent event,the probability of the sentences is : P(w(1), w(2)..., w(n-1), w(n))<br/><br/>
Using chain rule:<br/>
=<b>P(</b>w(1)<b>)</b> * <b>P(</b>w(2) | w(1)<b>)</b> * <b>P(</b>w(3) | w(1)w(2)<b>)</b> ... <b>P(</b>w(n) | w(1)w(2)…w(n-1)<b>)</b><br/><br/>
<b><u> Bigrams</u></b><br/>
We can avoid this very long calculation by approximating  that the probability of a given word depends only on the probability of its previous words. This assumption is called Markov assumption and such a model is called Markov model- bigrams. Bigrams can be generalized to the n-gram which looks at (n-1) words in the past. A bigram is a first-order Markov model. <br/>

Therefore , <br/>

     <b>P(</b>w(1), w(2)..., w(n-1), w(n)<b>)</b>= <b>P(</b>w(2)|w(1)<b>)</b> <b>P(</b>w(3)|w(2)<b>)</b> …. <b>P(</b>w(n)|w(n-1)<b>)</b><br/>
<br/>
We use (eos) tag to mark the beginning and end of a sentence.<br/>
A bigram table for a given corpus can be generated and used as a lookup table for calculating probability of sentences.<br/><br/>

Eg:
 
Corpus – (eos) You book a flight (eos) I read a book (eos) You read (eos) <br/><br/>

Bigram Table:<br/>
<table border="1">
<th></th><th>(eos)</th><th> you </th> <th> book </th> <th> a </th> <th> flight </th> <th> I </th> <th> read </th> </tr>
<tr>
<tr>
<th> (eos)</th><td> 0</td><td> 0.33</td><td>0</td><td> 0 </td> <td> 0 </td> <td> 0.25 </td><td> 0 </td> </tr>
<tr>
<th>you</th><td>0</td><td> 0 </td><td>0.5</td><td> 0 </td> <td> 0 </td> <td> 0</td> <td>0.5</td></tr>
<tr>
<th>book</th><td> 0.5 </td><td> 0</td><td>0</td><td> 0.5 </td> <td> 0 </td> <td> 0</td> <td>0</td></tr>
<tr>
<th>a</th><td> 0 </td><td> 0</td><td>0.5</td><td> 0 </td> <td> 0.5 </td> <td> 0</td> <td>0</td> </tr>  
<tr>
<th>flight</th><td> 1 </td><td> 0</td><td>0</td><td> 0 </td> <td> 0 </td> <td> 0</td> <td>0</td> </tr> 
<tr>
<th>I</th><td> 0 </td><td> 0</td><td>0</td><td> 0 </td> <td> 0 </td> <td> 0</td> <td>1</td> </tr>
<tr>
<th>read</th><td> 0.5 </td><td> 0</td><td>0</td><td> 0.5 </td> <td> 0 </td> <td> 0</td> <td>0</td> </tr> 
</table> 
 
<br/>
<br/>
<b>P(</b>(eos) you read a book (eos)<b>)</b><br/>
= <b>P(</b>you|eos<b>)</b> * <b>P(</b>read|you<b>)</b> * <b>P(</b>a|read<b>)</b> * <b>P(</b>book|a<b>)</b> * <b>P(</b>eos|book<b>)</b><br/>
= 0.33 * 0.5 * 0.5 * 0.5 * 0.5<br/>
=.020625<br/>
</div>
      </section>


      <section id="experiment-article-section-3">
        
        <div id="experiment-article-section-3-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/objective.jpg" />
	</div>
     
        <div id="experiment-article-section-3-heading" 
        class="heading">
          Objective
        </div>

        <div id="experiment-article-section-3-content" 
        class="content">

The objective of this experiment is to learn to calculate bigrams from a given corpus and calculate probability of a sentence.

<br><br><hr>

        </div>

      </section>


      <section id="experiment-article-section-4">

        <div id="experiment-article-section-4-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab.-->
	  <img src="../images/simulation.jpg" />
	</div>

        <div id="experiment-article-section-4-heading" 
        class="heading">
          Experiment
        </div>

        <div id="experiment-article-section-4-content" 
        class="content">
<div id="n-gram"></div>
        </div>

      </section>


        <section id="experiment-article-section-5">
      
          <div id="experiment-article-section-5-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab.-->
	    <img src="../images/quizzes.jpg" />
	  </div>

          <div id="experiment-article-section-5-heading" 
          class="heading">
            Quizzes
          </div>

          <div id="experiment-article-section-5-content" 
          class="content">
<b><u> Questions </u></b><br><br>
Q1. A trigram is a second-order Markov model. Derive the formula to calculate trigram probability. Next, calculate the trigram probabilities for the given corpus.
<center>(eos) Can I sit near you (eos) You can sit (eos) Sit near him (eos) I can sit you (eos) </center>
<br /><br/>
Q2. A character based N-gram is a set of n consecutive characters extracted from a word. It is generally used in measuring the similarity of character strings. Some of its applications are in spellcheckers, stemming, OCR error correction, etc. <br/><br/>

Given, four valid words:<br/>
(a) quote<br/>
(b) patient<br/>
(c) patent<br/>
(d) impatient<br/><br/>

Calculate the probability of occurrence of each word given below. Which of these represent the correct spelling? <br/>
(a) qotient (b) quotent (c) quotient<br/>
<br><br><hr>
</div>
        </section>

        <section id="experiment-article-section-6">
	  
          <div id="experiment-article-section-6-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab. -->
	    <img src="../images/procedure.jpg" />
	  </div>
	
          <div id="experiment-article-section-6-heading" 
          class="heading">
	    Procedure
	  </div>
	
          <div id="experiment-article-section-6-content" 
          class="content">
<b><u>STEP1: </u></b>Select a corpus  and click on <button>Generate bigram table</button><br>
<b><u>STEP2: </u></b>Fill up the table that is generated and hit <button>Submit</button><br>
<b><u>STEP3: </u></b>If incorrect (red), see the correct answer by clicking on show answer or repeat Step 2.<br>
<b><u>STEP4: </u></b>If correct (green), click on take a quiz and fill the correct answer
<br><br>
<hr>
	  </div>
	
        </section>
			
		
        <section id="experiment-article-section-7">
   
          <div id="experiment-article-section-7-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab.-->
	    <img src="../images/readings.jpg" />
	  </div>

          <div id="experiment-article-section-7-heading" 
          class="heading">
            Further Readings
          </div>

          <div id="experiment-article-section-7-content" 
          class="content">
<p><center><b>Speech and Language Processing - <i>An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition</i></b><br/>
BY: Daniel Jurafsky and James H. Martin<br/>
<i>Chapter 6</i></center></p>
<br/>
<br/>
<hr>
          </div>

        </section>

      </div>


    <!-- An article can have a sidebar that contain related 
    links and additional material (however it is kept optional 
    at this moment) -->
    <aside id="lab-article-sidebar" class="default">
      <!-- put the content that you want to appear in the 
      sidebar -->	
    </aside>


    <!-- Article footer can display related content and 
    additional links -->						
    <footer id="lab-article-footer" class="default">
      <!-- Put the content that you want to appear here -->
    </footer>

  </article>


  <!-- Links to other labs, about us page can be kept the lab 
  footer-->
  <footer id="lab-footer" class="default">
    <!-- Put the content here-->
  </footer>

</div>		

</body>
</html>
